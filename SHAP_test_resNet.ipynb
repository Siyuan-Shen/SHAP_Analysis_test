{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Net Construction\n",
    "\n",
    "ReLU_ACF = False\n",
    "Tanh_ACF = True\n",
    "GeLU_ACF = False\n",
    "Sigmoid_ACF = False\n",
    "\n",
    "def activation_function_table():\n",
    "    if ReLU_ACF == True:\n",
    "        return nn.ReLU()\n",
    "    elif Tanh_ACF == True:\n",
    "        return nn.Tanh()\n",
    "    elif GeLU_ACF == True:\n",
    "        return nn.GELU()\n",
    "    elif Sigmoid_ACF == True:\n",
    "        return nn.Sigmoid()\n",
    "\n",
    "activation_func = activation_function_table()\n",
    "\n",
    "\n",
    "def resnet_block_lookup_table(blocktype):\n",
    "    if blocktype == 'BasicBlock':\n",
    "        return BasicBlock\n",
    "    elif blocktype == 'Bottleneck':\n",
    "        return Bottleneck\n",
    "    else:\n",
    "        print(' Wrong Key Word! BasicBlock or Bottleneck only! ')\n",
    "        return None\n",
    "    \n",
    "\n",
    "class BasicBlock(nn.Module):  \n",
    "    \n",
    "    expansion = 1  \n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)  \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        if ReLU_ACF == True:\n",
    "            self.tanh =  nn.ReLU()\n",
    "        elif Tanh_ACF == True:\n",
    "            self.tanh = nn.Tanh()\n",
    "        elif GeLU_ACF == True:\n",
    "            self.tanh = nn.GELU()\n",
    "        elif Sigmoid_ACF == True:\n",
    "            self.tanh = nn.Sigmoid()\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = out + identity # out=F(X)+X\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class Bottleneck(nn.Module):  \n",
    "    # Three convolutional layers, F(x) and X have different dimensions.\n",
    "    \n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, groups=1, width_per_group=64):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        width = int(out_channel * (width_per_group / 64.)) * groups\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width,kernel_size=1, stride=1, bias=False)  # squeeze channels\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        # -----------------------------------------\n",
    "        self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups,kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        # -----------------------------------------\n",
    "        self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel * self.expansion,kernel_size=1, stride=1, bias=False)  # unsqueeze channels\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
    "\n",
    "        if ReLU_ACF == True:\n",
    "            self.tanh =  nn.ReLU()\n",
    "        elif Tanh_ACF == True:\n",
    "            self.tanh = nn.Tanh()\n",
    "        elif GeLU_ACF == True:\n",
    "            self.tanh = nn.GELU()\n",
    "        elif Sigmoid_ACF == True:\n",
    "            self.tanh = nn.Sigmoid()\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        identity = x\n",
    "       \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.Tanh(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.Tanh(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        # out=F(X)+X\n",
    "        out = out + identity\n",
    "        out = self.Tanh(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "  \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 nchannel, # initial input channel\n",
    "                 block,  # block types\n",
    "                 blocks_num,  \n",
    "                 num_classes=1,  \n",
    "                 include_top=True, \n",
    "                 groups=1,\n",
    "                 width_per_group=64):\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        self.in_channel = 64  \n",
    "\n",
    "        self.groups = groups\n",
    "        self.width_per_group = width_per_group\n",
    "        if ReLU_ACF == True:\n",
    "            self.actfunc =  nn.ReLU()\n",
    "        elif Tanh_ACF == True:\n",
    "            self.actfunc = nn.Tanh()\n",
    "        elif GeLU_ACF == True:\n",
    "            self.actfunc = nn.GELU()\n",
    "        elif Sigmoid_ACF == True:\n",
    "            self.actfunc = nn.Sigmoid()\n",
    "        \n",
    "        #self.conv1 = nn.Conv2d(nchannel, self.in_channel, kernel_size=7, stride=2,padding=3, bias=False)\n",
    "        #self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "\n",
    "        #self.tanh = nn.Tanh()\n",
    "        #self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        #self.layer0 = nn.Sequential(self.conv1,self.bn1,self.tanh,self.maxpool)\n",
    "        self.layer0 = nn.Sequential(nn.Conv2d(nchannel, self.in_channel, kernel_size=7, stride=2,padding=3, bias=False) #output size:6x6\n",
    "        #self.layer0 = nn.Sequential(nn.Conv2d(nchannel, self.in_channel, kernel_size=5, stride=1,padding=1, bias=False)\n",
    "        ,nn.BatchNorm2d(self.in_channel)\n",
    "        ,self.actfunc\n",
    "        ,nn.MaxPool2d(kernel_size=3, stride=2, padding=1)) # output 4x4\n",
    "\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
    "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=1)\n",
    "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=1)\n",
    "\n",
    "        if self.include_top: \n",
    "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  \n",
    "            \n",
    "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "   \n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channel * block.expansion))\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(block(self.in_channel,\n",
    "                            channel,\n",
    "                            downsample=downsample,\n",
    "                            stride=stride,\n",
    "                            groups=self.groups,\n",
    "                            width_per_group=self.width_per_group))\n",
    "\n",
    "        self.in_channel = channel * block.expansion # The input channel changed here!``\n",
    "        \n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(block(self.in_channel,\n",
    "                                channel,\n",
    "                                groups=self.groups,\n",
    "                                width_per_group=self.width_per_group))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.conv1(x)\n",
    "        #x = self.bn1(x)\n",
    "        #x = self.tanh(x)\n",
    "        #x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.include_top:  \n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            #x = self.actfunc(x)\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = np.load('test_observation_data.npy')\n",
    "training_data = np.load('test_training_data.npy')\n",
    "X_train = training_data[0:100,:,:,:]\n",
    "y_train = label_data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([100, 42, 11, 11])\n",
      "Epoch : 1/10, Iter : 1/10,  Loss: 0.2061\n",
      "Epoch : 1/10, Iter : 2/10,  Loss: 15.6132\n",
      "Epoch : 1/10, Iter : 3/10,  Loss: 15.4521\n",
      "Epoch : 1/10, Iter : 4/10,  Loss: 6.0780\n",
      "Epoch : 1/10, Iter : 5/10,  Loss: 2.2877\n",
      "Epoch : 1/10, Iter : 6/10,  Loss: 2.5414\n",
      "Epoch : 1/10, Iter : 7/10,  Loss: 7.1779\n",
      "Epoch : 1/10, Iter : 8/10,  Loss: 6.6867\n",
      "Epoch : 1/10, Iter : 9/10,  Loss: 0.4215\n",
      "Epoch : 1/10, Iter : 10/10,  Loss: 0.6789\n",
      "Epoch : 2/10, Iter : 1/10,  Loss: 1.2662\n",
      "Epoch : 2/10, Iter : 2/10,  Loss: 1.8282\n",
      "Epoch : 2/10, Iter : 3/10,  Loss: 0.9504\n",
      "Epoch : 2/10, Iter : 4/10,  Loss: 0.2434\n",
      "Epoch : 2/10, Iter : 5/10,  Loss: 0.4359\n",
      "Epoch : 2/10, Iter : 6/10,  Loss: 0.2305\n",
      "Epoch : 2/10, Iter : 7/10,  Loss: 1.1021\n",
      "Epoch : 2/10, Iter : 8/10,  Loss: 2.1208\n",
      "Epoch : 2/10, Iter : 9/10,  Loss: 0.7336\n",
      "Epoch : 2/10, Iter : 10/10,  Loss: 0.1997\n",
      "Epoch : 3/10, Iter : 1/10,  Loss: 0.4696\n",
      "Epoch : 3/10, Iter : 2/10,  Loss: 0.8157\n",
      "Epoch : 3/10, Iter : 3/10,  Loss: 1.1502\n",
      "Epoch : 3/10, Iter : 4/10,  Loss: 0.6085\n",
      "Epoch : 3/10, Iter : 5/10,  Loss: 0.4317\n",
      "Epoch : 3/10, Iter : 6/10,  Loss: 0.3530\n",
      "Epoch : 3/10, Iter : 7/10,  Loss: 1.8097\n",
      "Epoch : 3/10, Iter : 8/10,  Loss: 0.4214\n",
      "Epoch : 3/10, Iter : 9/10,  Loss: 1.2869\n",
      "Epoch : 3/10, Iter : 10/10,  Loss: 0.1507\n",
      "Epoch : 4/10, Iter : 1/10,  Loss: 0.2773\n",
      "Epoch : 4/10, Iter : 2/10,  Loss: 0.2951\n",
      "Epoch : 4/10, Iter : 3/10,  Loss: 1.1759\n",
      "Epoch : 4/10, Iter : 4/10,  Loss: 0.5337\n",
      "Epoch : 4/10, Iter : 5/10,  Loss: 0.7394\n",
      "Epoch : 4/10, Iter : 6/10,  Loss: 0.2431\n",
      "Epoch : 4/10, Iter : 7/10,  Loss: 0.6671\n",
      "Epoch : 4/10, Iter : 8/10,  Loss: 1.0306\n",
      "Epoch : 4/10, Iter : 9/10,  Loss: 0.0948\n",
      "Epoch : 4/10, Iter : 10/10,  Loss: 0.7466\n",
      "Epoch : 5/10, Iter : 1/10,  Loss: 1.0817\n",
      "Epoch : 5/10, Iter : 2/10,  Loss: 0.9500\n",
      "Epoch : 5/10, Iter : 3/10,  Loss: 0.2234\n",
      "Epoch : 5/10, Iter : 4/10,  Loss: 0.5430\n",
      "Epoch : 5/10, Iter : 5/10,  Loss: 0.8588\n",
      "Epoch : 5/10, Iter : 6/10,  Loss: 0.1823\n",
      "Epoch : 5/10, Iter : 7/10,  Loss: 0.6378\n",
      "Epoch : 5/10, Iter : 8/10,  Loss: 0.6206\n",
      "Epoch : 5/10, Iter : 9/10,  Loss: 0.1959\n",
      "Epoch : 5/10, Iter : 10/10,  Loss: 0.6257\n",
      "Epoch : 6/10, Iter : 1/10,  Loss: 1.1136\n",
      "Epoch : 6/10, Iter : 2/10,  Loss: 0.3294\n",
      "Epoch : 6/10, Iter : 3/10,  Loss: 0.3331\n",
      "Epoch : 6/10, Iter : 4/10,  Loss: 0.7400\n",
      "Epoch : 6/10, Iter : 5/10,  Loss: 0.2194\n",
      "Epoch : 6/10, Iter : 6/10,  Loss: 0.6270\n",
      "Epoch : 6/10, Iter : 7/10,  Loss: 0.1494\n",
      "Epoch : 6/10, Iter : 8/10,  Loss: 1.1302\n",
      "Epoch : 6/10, Iter : 9/10,  Loss: 1.1667\n",
      "Epoch : 6/10, Iter : 10/10,  Loss: 0.2422\n",
      "Epoch : 7/10, Iter : 1/10,  Loss: 0.7375\n",
      "Epoch : 7/10, Iter : 2/10,  Loss: 0.5735\n",
      "Epoch : 7/10, Iter : 3/10,  Loss: 1.4836\n",
      "Epoch : 7/10, Iter : 4/10,  Loss: 0.4050\n",
      "Epoch : 7/10, Iter : 5/10,  Loss: 0.5282\n",
      "Epoch : 7/10, Iter : 6/10,  Loss: 0.1426\n",
      "Epoch : 7/10, Iter : 7/10,  Loss: 0.5453\n",
      "Epoch : 7/10, Iter : 8/10,  Loss: 0.1559\n",
      "Epoch : 7/10, Iter : 9/10,  Loss: 0.4489\n",
      "Epoch : 7/10, Iter : 10/10,  Loss: 0.2515\n",
      "Epoch : 8/10, Iter : 1/10,  Loss: 0.4005\n",
      "Epoch : 8/10, Iter : 2/10,  Loss: 0.1445\n",
      "Epoch : 8/10, Iter : 3/10,  Loss: 0.3676\n",
      "Epoch : 8/10, Iter : 4/10,  Loss: 0.6154\n",
      "Epoch : 8/10, Iter : 5/10,  Loss: 0.9907\n",
      "Epoch : 8/10, Iter : 6/10,  Loss: 0.8350\n",
      "Epoch : 8/10, Iter : 7/10,  Loss: 0.2779\n",
      "Epoch : 8/10, Iter : 8/10,  Loss: 0.0922\n",
      "Epoch : 8/10, Iter : 9/10,  Loss: 1.1579\n",
      "Epoch : 8/10, Iter : 10/10,  Loss: 0.4659\n",
      "Epoch : 9/10, Iter : 1/10,  Loss: 0.2983\n",
      "Epoch : 9/10, Iter : 2/10,  Loss: 0.7813\n",
      "Epoch : 9/10, Iter : 3/10,  Loss: 0.1375\n",
      "Epoch : 9/10, Iter : 4/10,  Loss: 0.8951\n",
      "Epoch : 9/10, Iter : 5/10,  Loss: 0.2883\n",
      "Epoch : 9/10, Iter : 6/10,  Loss: 0.8796\n",
      "Epoch : 9/10, Iter : 7/10,  Loss: 0.3635\n",
      "Epoch : 9/10, Iter : 8/10,  Loss: 0.2800\n",
      "Epoch : 9/10, Iter : 9/10,  Loss: 0.3023\n",
      "Epoch : 9/10, Iter : 10/10,  Loss: 0.6870\n",
      "Epoch : 10/10, Iter : 1/10,  Loss: 0.8098\n",
      "Epoch : 10/10, Iter : 2/10,  Loss: 0.5162\n",
      "Epoch : 10/10, Iter : 3/10,  Loss: 0.4791\n",
      "Epoch : 10/10, Iter : 4/10,  Loss: 0.1373\n",
      "Epoch : 10/10, Iter : 5/10,  Loss: 0.2745\n",
      "Epoch : 10/10, Iter : 6/10,  Loss: 1.9447\n",
      "Epoch : 10/10, Iter : 7/10,  Loss: 0.2545\n",
      "Epoch : 10/10, Iter : 8/10,  Loss: 0.3227\n",
      "Epoch : 10/10, Iter : 9/10,  Loss: 0.5073\n",
      "Epoch : 10/10, Iter : 10/10,  Loss: 0.9541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Epoch   = 10\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):  # 'Characterizes a dataset for PyTorch'\n",
    "    '''\n",
    "    This class is for training datasets. It is used for the global datasets, which is continuous data.\n",
    "    '''\n",
    "    def __init__(self, traindata, truedata):  # 'Initialization' Data Loading\n",
    "        '''\n",
    "\n",
    "        :param traindata:\n",
    "            Training data.\n",
    "        :param truedata:\n",
    "            Ture data to learn.\n",
    "        :param beginyear:\n",
    "            The begin year.\n",
    "        :param endyear:\n",
    "            The end year.\n",
    "        :param nsite:\n",
    "            The number of sites. For example, for overall observation it is 10870.\n",
    "        '''\n",
    "        super(Dataset, self).__init__()\n",
    "        self.traindatasets = torch.Tensor(traindata)  # Read training data from npy file\n",
    "        self.truedatasets = torch.Tensor(truedata)\n",
    "        print(self.truedatasets.shape)\n",
    "        print(self.traindatasets.shape)\n",
    "        self.transforms = transform  # 转为tensor形式\n",
    "        self.shape = self.traindatasets.shape\n",
    "    def __getitem__(self, index):  # 'Generates one sample of data'\n",
    "        # Select sample\n",
    "        traindata = self.traindatasets[index, :, :]\n",
    "        truedata = self.truedatasets[index]\n",
    "        return traindata, truedata\n",
    "        # Load data and get label\n",
    "    def __len__(self):  # 'Denotes the total number of samples'\n",
    "        return self.traindatasets.shape[0]  # Return the total number of dataset\n",
    "\n",
    "def train(model, X_train, y_train,BATCH_SIZE, learning_rate):\n",
    "    train_loader = DataLoader(Dataset(X_train, y_train), BATCH_SIZE, shuffle=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.9)\n",
    "    for epoch in range(Epoch):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            images = images.to(device)\n",
    "            labels = torch.squeeze(labels.type(torch.FloatTensor))\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()  \n",
    "            outputs = model(images) \n",
    "            outputs = torch.squeeze(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  \n",
    "            optimizer.step() \n",
    "            print('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' % (epoch + 1, Epoch,\n",
    "                                                                    i + 1, len(X_train) // BATCH_SIZE,\n",
    "                                                                    loss.item()))\n",
    "    return \n",
    "\n",
    "device = torch.device('cpu')\n",
    "cnn_model = ResNet(nchannel=42, block=BasicBlock,blocks_num=[1,1,1,1]).to(device)\n",
    "train(cnn_model, X_train, y_train, Epoch, learning_rate=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The SHAP explanations do not sum up to the model's output! This is either because of a rounding error or because an operator in your computation graph was not fully supported. If the sum difference of %f is significant compared to the scale of your model outputs, please post as a github issue, with a reproducible example so we can debug it. Used framework: pytorch - Max. diff: 0.07501436083411883 - Tolerance: 0.01",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m Data_to_Explain  \u001b[38;5;241m=\u001b[39m Data_to_Explain\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m CNNModel_Explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mDeepExplainer(model\u001b[38;5;241m=\u001b[39mcnn_model,data\u001b[38;5;241m=\u001b[39mBack_Ground_Data)\n\u001b[0;32m----> 8\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mCNNModel_Explainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mData_to_Explain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/shap/explainers/_deep/__init__.py:159\u001b[0m, in \u001b[0;36mDeepExplainer.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, check_additivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/shap/explainers/_deep/deep_pytorch.py:214\u001b[0m, in \u001b[0;36mPyTorchDeep.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    212\u001b[0m             model_output_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39mX)\n\u001b[0;32m--> 214\u001b[0m     \u001b[43m_check_additivity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_phis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output_phis, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# in this case we have multiple inputs and potentially multiple outputs\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output_phis[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/shap/explainers/_deep/deep_utils.py:20\u001b[0m, in \u001b[0;36m_check_additivity\u001b[0;34m(explainer, model_output_values, output_phis)\u001b[0m\n\u001b[1;32m     16\u001b[0m         diffs \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m output_phis[t][i]\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, output_phis[t][i]\u001b[38;5;241m.\u001b[39mndim)))\n\u001b[1;32m     18\u001b[0m maxdiff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(diffs)\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m maxdiff \u001b[38;5;241m<\u001b[39m TOLERANCE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe SHAP explanations do not sum up to the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms output! This is either because of a \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     21\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrounding error or because an operator in your computation graph was not fully supported. If \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     22\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe sum difference of \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m is significant compared to the scale of your model outputs, please post \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     23\u001b[0m                             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas a github issue, with a reproducible example so we can debug it. Used framework: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexplainer\u001b[38;5;241m.\u001b[39mframework\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Max. diff: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaxdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Tolerance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTOLERANCE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The SHAP explanations do not sum up to the model's output! This is either because of a rounding error or because an operator in your computation graph was not fully supported. If the sum difference of %f is significant compared to the scale of your model outputs, please post as a github issue, with a reproducible example so we can debug it. Used framework: pytorch - Max. diff: 0.07501436083411883 - Tolerance: 0.01"
     ]
    }
   ],
   "source": [
    "# SHAP Value Analysis\n",
    "cnn_model.eval()\n",
    "Back_Ground_Data = torch.Tensor(training_data[0:100,:,:,:])\n",
    "Data_to_Explain  = torch.Tensor(training_data[100:103,:,:,:])\n",
    "Back_Ground_Data = Back_Ground_Data.to(device)\n",
    "Data_to_Explain  = Data_to_Explain.to(device)\n",
    "CNNModel_Explainer = shap.DeepExplainer(model=cnn_model,data=Back_Ground_Data)\n",
    "shap_values = CNNModel_Explainer.shap_values(Data_to_Explain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
